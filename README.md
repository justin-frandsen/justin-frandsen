# Justin Frandsen

Ph.D. student in Cognition and Cognitive Neuroscience at **Texas A&M University**. My research focuses on the mechanisms of visual attention and learning in complex, naturalistic environments. I use behavioral methods, eye tracking, and computational modeling to investigate how people extract structure from the visual world.

## Research Interests
- Visual attention and statistical learning  
- Scene grammar and object-location regularities  
- Aversive conditioning and attentional bias  
- Saliency modeling and image-based analysis  

## Current Projects
- **Statistical Learning in Visual Search**  
  Investigating how learned regularities in object locations and scene context influence search behavior.  

- **Saliency and Threat Detection in Fire Imagery**  
  In collaboration with the Yorzinski Lab, applying saliency models (e.g., GBVS, DeepGaze) and image segmentation techniques to examine how fire draws visual attention.  

- **Aversive Learning and Distractor Suppression**  
  Studying how negative outcomes shape attentional selection and resistance to distraction.  

## Tools & Methods
- Programming: Python, MATLAB, R  
- Experiment design: Psychtoolbox, PsychoPy  
- Eye tracking: EyeLink 1000, DataViewer  
- Statistical analysis: pandas, NumPy, tidyverse, SPSS, JASP  
- Image processing: OpenCV, scikit-image  
- Version control: Git, GitHub  

## Contact
📧 justin.frandsen@tamu.edu
🌐 [GitHub](https://github.com/justin-frandsen)
🔗 [LinkedIn](https://www.linkedin.com/in/justin-frandsen/)
📚 [Google Scholar](https://scholar.google.com/citations?user=6svOSbIAAAAJ&hl=en)
